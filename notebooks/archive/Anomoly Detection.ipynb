{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import junoutils\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ifst = sklearn.ensemble.IsolationForest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = junoutils.openPickle('summary_withemb.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_prefixes = ['__v']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for col in s.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = ['email','tSNE_x', 'tSNE_y', 'suspected_fraud', 'fraud_count', 'value_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "\n",
    "for c in s.columns:\n",
    "    if 'value' in c:\n",
    "        values.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = s.drop(drops+values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_scaled = junoutils.scaleDf(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Null columns\")\n",
    "for col in sd:\n",
    "    if np.sum(pd.isnull(sd[col])) > 0:\n",
    "        print(col, np.sum(np.isnull(sd[col])))\n",
    "\n",
    "print(\"Inf Columns:\")\n",
    "for col in sd:\n",
    "\n",
    "    if np.sum(np.isfinite(sd[col]) == False) > 0:\n",
    "        print(col, np.sum(np.isfinite(sd[col] == False)) > 0)\n",
    "\n",
    "print(\"Columns could not convert to int32\")\n",
    "for col in sd:\n",
    "    try:\n",
    "        sd[col] = sd[col].astype('float32')\n",
    "    except:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_percentage = []\n",
    "caught = []\n",
    "percent_caught = []\n",
    "number_to_check = []\n",
    "bang_for_buck = []\n",
    "\n",
    "for con in [0.001, 0.01, 0.1, 0.2, 0.3]:\n",
    "\n",
    "    ifst = sklearn.ensemble.IsolationForest(contamination=con)#contamination=0.01)\n",
    "    ifst.fit(sd_scaled)\n",
    "    anomoly = ifst.predict(X=sd_scaled)\n",
    "\n",
    "    s['anomoly'] = anomoly\n",
    "\n",
    "    anomoly_emails = list(s['email'][s['anomoly'] == -1])\n",
    "    flagged_emails = list(s['email'][s['suspected_fraud'] == True])\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for email in flagged_emails:\n",
    "        if email in anomoly_emails:\n",
    "            #print(email)\n",
    "            count +=1\n",
    "    \n",
    "    caught.append(count)\n",
    "    fraud_percentage.append(con)\n",
    "    percent_caught.append(count/len(flagged_emails))\n",
    "    number_to_check.append(len(anomoly_emails))\n",
    "    bb = count/len(flagged_emails)/len(anomoly_emails)\n",
    "    bang_for_buck.append(bb)\n",
    "\n",
    "    print('Contamination: {}, Percent Caught: {}, Percent Caught/Number To Check: {}'.format(con, count/len(flagged_emails), count/len(flagged_emails)/len(anomoly_emails)))\n",
    "    \n",
    "bb = np.array(bang_for_buck)\n",
    "    \n",
    "results = pd.DataFrame({'Assumed Fraud Percentage': fraud_percentage,\n",
    "                        'Number Caught': caught,\n",
    "                        'Percent Caught of Known Accounts': percent_caught,\n",
    "                        'Number to Check': number_to_check,\n",
    "                        'Bang for Your Buck': (bb-np.min(bb))/(np.max(bb)-np.min(bb))})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sklearn.svm.OneClassSVM()\n",
    "ifst = sklearn.svm.OneClassSVM()\n",
    "ifst.fit(sd_scaled)\n",
    "anomoly = ifst.predict(X=sd_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anomoly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "rcParams['figure.figsize'] = 14, 8\n",
    "RANDOM_SEED = 42\n",
    "LABELS = [\"Normal\", \"Fraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['email']\n",
    "\n",
    "for col in sd_scaled:\n",
    "    if 'fraud' in col or 'value' in col:\n",
    "        print(col)\n",
    "        drop_cols.append(col)\n",
    "        \n",
    "drop_cols = list(set(drop_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sd_scaled\n",
    "data['fraud'] = s['suspected_fraud']\n",
    "data['email'] = s['email']\n",
    "X_train, X_test = train_test_split(data, test_size=0.2, random_state=RANDOM_SEED)\n",
    "X_train = X_train[X_train.fraud == 0]\n",
    "X_train = X_train.drop(drop_cols, axis=1)\n",
    "y_test = X_test['fraud']\n",
    "X_test = X_test.drop(drop_cols, axis=1)\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "X_train.shape\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "encoding_dim = int(input_dim/10)\n",
    "\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "encoder = Dense(encoding_dim, activation=\"tanh\", \n",
    "                activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "encoder = Dense(int(encoding_dim / 2), activation=\"relu\")(encoder)\n",
    "decoder = Dense(int(encoding_dim / 2), activation='tanh')(encoder)\n",
    "decoder = Dense(input_dim, activation='relu')(decoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nb_epoch = 100\n",
    "batch_size = 32\n",
    "autoencoder.compile(optimizer='adam', \n",
    "                    loss='mean_squared_error', \n",
    "                    metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath=\"model.h5\",\n",
    "                               verbose=0,\n",
    "                               save_best_only=True)\n",
    "# tensorboard = TensorBoard(log_dir='./logs',\n",
    "#                           histogram_freq=0,\n",
    "#                           write_graph=True,\n",
    "#                           write_images=True)\n",
    "history = autoencoder.fit(X_train, X_train,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(X_test, X_test),\n",
    "                    verbose=1,\n",
    "                    callbacks=[checkpointer]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = autoencoder.predict(X_test)\n",
    "mse = np.mean(np.power(X_test - predictions, 2), axis=1)\n",
    "error_df = pd.DataFrame({'reconstruction_error': mse,\n",
    "                        'true_class': y_test})\n",
    "error_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import (confusion_matrix, precision_recall_curve, auc,\n",
    "                             roc_curve, recall_score, classification_report, f1_score,\n",
    "                             precision_recall_fscore_support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(error_df.true_class, error_df.reconstruction_error)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, label='AUC = %0.4f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.001, 1])\n",
    "plt.ylim([0, 1.001])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, th = precision_recall_curve(error_df.true_class, error_df.reconstruction_error)\n",
    "plt.plot(recall, precision, 'b', label='Precision-Recall curve')\n",
    "plt.title('Recall vs Precision')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(th, precision[1:], 'b', label='Threshold-Precision curve')\n",
    "plt.title('Precision for different threshold values')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(th, recall[1:], 'b', label='Threshold-Recall curve')\n",
    "plt.title('Recall for different threshold values')\n",
    "plt.xlabel('Reconstruction error')\n",
    "plt.ylabel('Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1\n",
    "\n",
    "groups = error_df.groupby('true_class')\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for name, group in groups:\n",
    "    ax.plot(group.index, group.reconstruction_error, marker='o', ms=3.5, linestyle='',\n",
    "            label= \"Fraud\" if name == 1 else \"Normal\")\n",
    "ax.hlines(threshold, ax.get_xlim()[0], ax.get_xlim()[1], colors=\"r\", zorder=100, label='Threshold')\n",
    "ax.legend()\n",
    "plt.title(\"Reconstruction error for different classes\")\n",
    "plt.ylabel(\"Reconstruction error\")\n",
    "plt.xlabel(\"Data point index\")\n",
    "plt.show();\n",
    "\n",
    "y_pred = [1 if e > threshold else 0 for e in error_df.reconstruction_error.values]\n",
    "conf_matrix = confusion_matrix(error_df.true_class, y_pred)\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_scaled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = sd_scaled.drop(drop_cols, axis=1)\n",
    "c = autoencoder.predict(d)\n",
    "\n",
    "squared_error = np.power(d - c, 2)\n",
    "mse = np.mean(squared_error, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_squared_error = np.apply_along_axis(arr=squared_error, axis=1, func1d=np.max)\n",
    "col_of_biggest_squared_error = np.array(d.columns[np.apply_along_axis(arr=squared_error, axis=1, func1d=np.argmax)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomoly = mse > 0.08\n",
    "\n",
    "predicted_emails = list(sd_scaled.email[anomoly == True])\n",
    "max_sqe = list(max_squared_error[anomoly == True])\n",
    "col_biggest_error = col_of_biggest_squared_error[anomoly == True]\n",
    "\n",
    "count = 0\n",
    "\n",
    "for email in flagged_emails:\n",
    "        if email in predicted_emails:\n",
    "            count +=1\n",
    "        else:\n",
    "            print(email)\n",
    "            \n",
    "print('Found {} out of {} or {} percent, {} other users flagged'.format(count, len(flagged_emails), count/len(flagged_emails), len(predicted_emails)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'email': predicted_emails,\n",
    "                        'prediction_error': mse[anomoly],\n",
    "                        'column_biggest_error': col_biggest_error,\n",
    "                        'biggest_error_value': max_sqe}).sort_values(by='prediction_error', ascending=False).reset_index(drop=True)\n",
    "results['known fraudster'] = results.email.apply(lambda x: True if x in flagged_emails else False)\n",
    "results = results.reset_index(drop=True)\n",
    "results = results.dropna()\n",
    "\n",
    "results.to_csv('anomaly_detection_results.csv')\n",
    "\n",
    "results.to_html('anomaly_detection_results.html')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.column_biggest_error.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(results.prediction_error, hist=False, rug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
