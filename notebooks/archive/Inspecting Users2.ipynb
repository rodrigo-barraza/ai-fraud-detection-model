{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for auto-reloading extensions - helpful if you're writing and testing a package\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# for inline plotting in python using matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for easier plots - also makes matplotlib plots look nicer by default\n",
    "import seaborn as sns\n",
    "\n",
    "# set up for using plotly offline without an API key - great for interactive plots\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# for numerical work\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pymongo\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "\n",
    "from pandas.io.json import json_normalize\n",
    "from pymongo import MongoClient\n",
    "\n",
    "import pickle\n",
    "\n",
    "from confluent_kafka import Producer\n",
    "\n",
    "import bson\n",
    "from bson import json_util\n",
    "\n",
    "import math\n",
    "\n",
    "import event_processing\n",
    "\n",
    "clean_events = event_processing.clean_events\n",
    "\n",
    "# load the database credentials from file\n",
    "with open('../creds/creds.json') as json_data:\n",
    "    creds = json.load(json_data)\n",
    "    \n",
    "client = MongoClient(creds['connection_string'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_horizontal_bar(label, value, df):\n",
    "\n",
    "    data = [go.Bar(\n",
    "        x=df[value].values,\n",
    "        y=df[label].values,\n",
    "        orientation='h')]\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title='{} by {}'.format(value, label),\n",
    "        yaxis={'automargin': True})\n",
    "\n",
    "    fig = go.Figure(data, layout)\n",
    "\n",
    "    iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = [item['email'] for item in client['production']['emailBlacklistCollection'].find() if item['level'] == 'BLOCKED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist_events = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in blacklist:\n",
    "    blacklist_events[user] = list(client['production']['eventCollection'].find({'metadata.email': user}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in blacklist:\n",
    "    blacklist_events[user] = clean_events(blacklist_events[user])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_list = []\n",
    "\n",
    "for u in blacklist_events.keys():\n",
    "    \n",
    "    events_list += blacklist_events[u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edf = json_normalize(events_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in edf.columns: print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def horizontal_categorical_barplot(group, value, df, agg_func):\n",
    "    \n",
    "    grouped = df.groupby(group, as_index=False).agg({value: agg_func}).sort_values(value, ascending=True).reset_index(drop=True)\n",
    "\n",
    "    plot_horizontal_bar(group, value, grouped)\n",
    "    \n",
    "\n",
    "def expand_datetime(time_column, df):\n",
    "    \n",
    "    df[time_column+'_year'] = df[time_column].apply(lambda time: time.year)\n",
    "    df[time_column+'_month'] = df[time_column].apply(lambda time: time.month)\n",
    "    df[time_column+'_day'] = df[time_column].apply(lambda time: time.day)\n",
    "    df[time_column+'_hour'] = df[time_column].apply(lambda time: time.hour)\n",
    "    df[time_column+'_weekday'] = df[time_column].apply(lambda time: time.weekday())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_categorical_barplot(group='user_email', value='card_last_digits', df=edf, agg_func=pd.Series.nunique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_categorical_barplot(group='user_email', value='billing_street', df=edf, agg_func=pd.Series.nunique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edf = expand_datetime('created', edf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edf[[col for col in edf.columns if 'created' in col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import featuretools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import shelve\n",
    "from bson import json_util\n",
    "import time\n",
    "\n",
    "events_filepath  = '../data/events.json'\n",
    "clean_events_filepath = '../data/clean_events.json'\n",
    "latest_event = '../data/latest_event.json'\n",
    "\n",
    "\n",
    "def append_events(events, filepath):\n",
    "    \n",
    "    events_string = ', '.join(['{}'.format(json_util.dumps(event)) for event in events])\n",
    "    \n",
    "    if os.path.isfile(filepath):\n",
    "    \n",
    "        with open (filepath, mode=\"r+\") as file:\n",
    "            file.seek(os.stat(filepath).st_size -1)\n",
    "            file.write(\",{}]\".format(events_string))\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        with open (filepath, mode=\"w+\") as file:\n",
    "            #file.seek(os.stat(filepath).st_size -1)\n",
    "            file.write(\"[{}]\".format(events_string))\n",
    "\n",
    "            \n",
    "def update_latest_record(event, filepath):\n",
    "    \n",
    "    \n",
    "    latest_json = {\n",
    "        'latest_event_time': event['created'],\n",
    "        'latest_event_id': event['_id']\n",
    "    }\n",
    "    \n",
    "    latest_json = json_util.loads(json_util.dumps(latest_json))\n",
    "    \n",
    "    \n",
    "    if os.path.isfile(filepath):\n",
    "        \n",
    "        with open (filepath, mode=\"r+\") as file:\n",
    "            previous_json = json_util.loads(file.read())\n",
    "            \n",
    "            latest_json = {\n",
    "                'latest_event_time': none_max(json_util.loads(json_util.dumps(event['created'])), previous_json['latest_event_time']),\n",
    "                'latest_event_id': none_max(event['_id'],previous_json['latest_event_id'])\n",
    "            }\n",
    "            \n",
    "            \n",
    "            file.seek(0)\n",
    "            file.write(json_util.dumps(latest_json))\n",
    "            file.truncate()\n",
    "            file.close()\n",
    "            \n",
    "    else:\n",
    "    \n",
    "        with open (filepath, mode=\"w+\") as file:\n",
    "            \n",
    "            file.seek(0)\n",
    "            file.write(json_util.dumps(latest_json))\n",
    "            file.truncate()\n",
    "            file.close()\n",
    "\n",
    "            \n",
    "def get_latest_event_info(filepath):\n",
    "    \n",
    "    if os.path.isfile(filepath):\n",
    "        \n",
    "        with open (filepath, mode=\"r+\") as file:\n",
    "            previous_json = json_util.loads(file.read())\n",
    "            \n",
    "        return previous_json['latest_event_id'], previous_json['latest_event_time']\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        return None, None\n",
    "        \n",
    "\n",
    "def none_max(a,b):\n",
    "    \n",
    "    if a == None and b == None:\n",
    "        return None\n",
    "    \n",
    "    if a == None:\n",
    "        return b\n",
    "    \n",
    "    if b == None:\n",
    "        return a\n",
    "    \n",
    "    return max(a,b)\n",
    "\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "processed = 0\n",
    "latest_event_id, latest_event_time = get_latest_event_info(latest_event)\n",
    "\n",
    "                       \n",
    "def process_events(events):\n",
    "\n",
    "    # clean_event = event_processing.clean_event(event)\n",
    "\n",
    "    append_events(events, events_filepath)\n",
    "    append_events([event_processing.clean_event(event) for event in events], clean_events_filepath)\n",
    "    update_latest_record(events[-1], latest_event)\n",
    "    global latest_event_id\n",
    "    latest_event_id = none_max(latest_event_id, events[-1]['_id'])\n",
    "\n",
    "    global latest_event_time\n",
    "    latest_event_time = none_max(latest_event_time, json_util.loads(json_util.dumps(events[-1]['created'])))\n",
    "\n",
    "    global processed\n",
    "    processed += len(events)\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "        \n",
    "    print('{} events processed in {} seconds or {} events per second'.format(processed, elapsed, processed/elapsed))\n",
    "\n",
    "                       \n",
    "has_events = True\n",
    "batch_size = 1000\n",
    "                       \n",
    "while has_events:\n",
    "                  \n",
    "    if latest_event_id == None:\n",
    "        print(\"Starting from beginning of collection.\")\n",
    "        events = list(client['production']['eventCollection'].find().limit(batch_size))\n",
    "\n",
    "    else:\n",
    "        print(\"Starting from event id {}\".format(latest_event_id))\n",
    "        events = list(client['production']['eventCollection'].find({'_id': {'$gt': latest_event_id}}).limit(batch_size))\n",
    "\n",
    "    if len(events) == 0:\n",
    "        has_events = False\n",
    "        print('Done')\n",
    "    else:\n",
    "        process_events(events)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/clean_events.json') as json_data:\n",
    "    \n",
    "    clean_events = json_data.read()\n",
    "    \n",
    "    clean_events = clean_events.replace('}{', '},{').replace(',,',',')\n",
    "    \n",
    "    clean_events = json_util.loads(clean_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_events = pd.DataFrame(clean_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_events = expand_datetime('created', clean_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in sorted(clean_events.columns): print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_events['day'] = clean_events.apply(lambda row: datetime.datetime(row['created_year'],row['created_month'],row['created_day']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_by_day(day_col, group, value, agg_func, df):\n",
    "\n",
    "    grouped = df.groupby([group,day_col])[value].aggregate({value: agg_func}).reset_index()\n",
    "    \n",
    "    return grouped\n",
    "\n",
    "cal = agg_by_day('day', 'category_action_label','_id', 'count', df= clean_events)\n",
    "ca = agg_by_day('day', 'category_action','_id', 'count', df= clean_events)\n",
    "cl = agg_by_day('day', 'category_label','_id', 'count', df= clean_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_series(df, time, category, value):\n",
    "    \n",
    "    data = [go.Scatter(\n",
    "        x=df[df[category] == cat][time],\n",
    "        y=df[df[category] == cat][value],\n",
    "        name = cat) for cat in sorted(df[category].unique())]\n",
    "    \n",
    "    plot(data)\n",
    "    \n",
    "plot_time_series(df=cal, time='day', category='category_action_label', value='_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades = clean_events[(clean_events.event_category == 'trade') & (clean_events.trade_result.isin(['accepted','rejected']))].dropna(axis=1, how='all')\n",
    "\n",
    "trades['fiat_currency_rate'] = trades.fiat_currency_value / trades.cryptocurrency_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zec = trades[['created','fiat_currency_rate','fiat_currency_value','cryptocurrency','cryptocurrency_amount','trade_latest_price','category_action_label','trade_result','user_email']]\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "display(zec[zec.user_email == 'mike@4am.ca'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [go.Scatter(x=zec[zec.category_action_label == category].created, \n",
    "            y=zec[zec.category_action_label == category].fiat_currency_rate, \n",
    "            name=category,\n",
    "            text=zec[zec.category_action_label == category].user_email) for category in sorted(zec.category_action_label.unique())] \n",
    "\n",
    "iplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trades = clean_events[(clean_events.event_category == 'trade') & \n",
    "                          (clean_events.trade_result.isin(['accepted'])) &\n",
    "                          (clean_events.category_action_label.isin(['trade_place-market-order_sell','trade_place-market-order_buy']))].dropna(axis=1, how='all')\n",
    "\n",
    "all_trades['fiat_currency_rate'] = all_trades.fiat_currency_value / all_trades.cryptocurrency_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in all_trades.columns: print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_trades = all_trades[['created','category_action_label','user_email','cryptocurrency_amount','cryptocurrency','trade_latest_price']].sort_values(['user_email','cryptocurrency','created']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_trades['previous_action'] = user_trades.groupby(['user_email', 'cryptocurrency'])['category_action_label'].shift(1)\n",
    "user_trades['previous_price'] = user_trades.groupby(['user_email', 'cryptocurrency'])['trade_latest_price'].shift(1)\n",
    "user_trades['previous_time'] = user_trades.groupby(['user_email', 'cryptocurrency'])['created'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_trades = user_trades.sort_values('created').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sell_high_buy_low = user_trades[(user_trades.category_action_label == 'trade_place-market-order_buy') & \n",
    "            (user_trades.previous_action == 'trade_place-market-order_sell') &\n",
    "            (user_trades.trade_latest_price < user_trades.previous_price)]\n",
    "\n",
    "sell_high_buy_low['reduction'] = (sell_high_buy_low['trade_latest_price'] - sell_high_buy_low['previous_price'])/sell_high_buy_low['previous_price']\n",
    "\n",
    "sell_high_buy_low.created = pd.to_datetime([x.astype(datetime.datetime) for x in sell_high_buy_low.created.values])\n",
    "sell_high_buy_low.previous_time = pd.to_datetime([x.astype(datetime.datetime) for x in sell_high_buy_low.previous_time.values])\n",
    "\n",
    "#sell_high_buy_low['time_diff'] = sell_high_buy_low.created - sell_high_buy_low.previous_time\n",
    "\n",
    "sell_high_buy_low['time_difference'] = (sell_high_buy_low.created - sell_high_buy_low.previous_time).apply(lambda x: x.total_seconds())\n",
    "\n",
    "sell_high_buy_low = sell_high_buy_low[(sell_high_buy_low.reduction < -0.10) & (sell_high_buy_low.time_difference < 60*60)]\n",
    "\n",
    "sell_high_buy_low = sell_high_buy_low[sell_high_buy_low.user_email == 'mike@4am.ca']\n",
    "\n",
    "sell_high_buy_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades = clean_events[(clean_events.event_category == 'trade') & (clean_events.trade_latest_price.isnull() == False)].dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades = trades[['created','category_action_label','cryptocurrency','trade_latest_price']]\n",
    "trades['type'] = trades['cryptocurrency']#+'_'+trades['category_action_label']\n",
    "\n",
    "trades = trades.sort_values('created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [go.Scatter(\n",
    "        x=trades[trades.type == tradetype]['created'],\n",
    "        y=trades[trades.type == tradetype]['trade_latest_price'],\n",
    "        name=tradetype) for tradetype in sorted(trades.type.unique())]\n",
    "\n",
    "layout = go.Layout(title='Last Traded Price by Cryptocurrency',\n",
    "                  yaxis={'title': 'Last Traded Price'},\n",
    "                  xaxis={'title': 'Time'})\n",
    "\n",
    "\n",
    "plot(go.Figure(data=data, layout=layout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = list(client['production']['eventCollection'].find({'eventCategory': 'trade'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_trades = json_normalize(events)\n",
    "\n",
    "raw_trades = raw_trades[['_id','created','metadata.email','eventAction','eventLabel','metadata.instrument','metadata.tradesResponse','metadata.lastTradedPx']]\n",
    "\n",
    "raw_trades = raw_trades[raw_trades['metadata.tradesResponse'] == \"Accepted\"]\n",
    "\n",
    "raw_trades = raw_trades.sort_values(by='created')\n",
    "\n",
    "raw_trades['previous_metadata.lastTradedPx'] = raw_trades.groupby('metadata.instrument')['metadata.lastTradedPx'].shift(1)\n",
    "\n",
    "raw_trades['previous_eventAction'] = raw_trades.groupby('metadata.instrument')['eventAction'].shift(1)\n",
    "raw_trades['previous_eventLabel'] = raw_trades.groupby('metadata.instrument')['eventLabel'].shift(1)\n",
    "\n",
    "raw_trades['percentage_price_difference'] = ((raw_trades['metadata.lastTradedPx'] - raw_trades['previous_metadata.lastTradedPx'])/raw_trades['previous_metadata.lastTradedPx']).astype(float)\n",
    "\n",
    "raw_trades = raw_trades[np.abs(raw_trades.percentage_price_difference) > 0.5]\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "\n",
    "raw_trades.to_csv('large_price_fluctuations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [go.Scatter(\n",
    "        x=raw_trades[raw_trades['metadata.instrument'] == tradetype]['created'],\n",
    "        y=raw_trades[raw_trades['metadata.instrument'] == tradetype]['metadata.lastTradedPx'],\n",
    "        name=tradetype) for tradetype in sorted(raw_trades['metadata.instrument'].unique())]\n",
    "\n",
    "layout = go.Layout(title='Last Traded Price by Cryptocurrency',\n",
    "                  yaxis={'title': 'Last Traded Price'},\n",
    "                  xaxis={'title': 'Time'})\n",
    "\n",
    "\n",
    "plot(go.Figure(data=data, layout=layout))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
