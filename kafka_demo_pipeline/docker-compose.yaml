---
version: '2'
services:
  # apache zookeeper instance for cluster management
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    hostname: zookeeper
    ports:
      - '32181:32181'
    environment:
      ZOOKEEPER_CLIENT_PORT: 32181
      ZOOKEEPER_TICK_TIME: 2000
    extra_hosts:
      - "moby:127.0.0.1"
      - "localhost: 127.0.0.1"
  
  # kafka broker
  kafka:
    image: confluentinc/cp-enterprise-kafka:latest
    hostname: kafka
    ports:
      - '9092:9092'
      - '29092:29092'
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:32181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: kafka:29092
      CONFLUENT_METRICS_REPORTER_ZOOKEEPER_CONNECT: zookeeper:32181
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      CONFLUENT_METRICS_ENABLE: 'true'
      CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'
    extra_hosts:
      - "moby:127.0.0.1"
      - "localhost: 127.0.0.1"
  
  # schema registry for working with apache avro format
  schema-registry:
    image: confluentinc/cp-schema-registry:latest
    hostname: schema-registry
    depends_on:
      - zookeeper
      - kafka
    ports:
      - '8081:8081'
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: zookeeper:32181
    extra_hosts:
      - "moby:127.0.0.1"
      - "localhost: 127.0.0.1"
  
  # rest interface for kafka cluster
  kafka-rest:
    image: confluentinc/cp-kafka-rest:latest
    hostname: kafka-rest
    ports:
      - 29080:29080
    depends_on:
      - zookeeper
      - kafka
      - schema-registry
    environment:
      KAFKA_REST_ZOOKEEPER_CONNECT: zookeeper:32181
      KAFKA_REST_LISTENERS: http://kafka-rest:29080
      KAFKA_REST_SCHEMA_REGISTRY_URL: http://schema-registry:29081
      KAFKA_REST_HOST_NAME: kafka-rest
      KAFKA_REST_BOOTSTRAP_SERVERS: kafka:29092
    extra_hosts:
      - "moby:127.0.0.1"
      - "localhost: 127.0.0.1"

  # # This "container" is a workaround to pre-create topics as by default topics cannot be
  # auto created inside the cp-kafka docker image
  kafka-create-topics:
    image: confluentinc/cp-kafka:4.1.0
    depends_on:
      - kafka
    hostname: kafka-create-topics
    # We defined a dependency on "kafka", but `depends_on` will NOT wait for the
    # dependencies to be "ready" before starting the "kafka-create-topics"
    # container;  it waits only until the dependencies have started.  Hence we
    # must control startup order more explicitly.
    # See https://docs.docker.com/compose/startup-order/
    command: "bash -c 'echo Waiting for Kafka to be ready... && \
                       cub kafka-ready -b kafka:29092 1 120 && \
                       kafka-topics --create --topic events --if-not-exists --zookeeper zookeeper:32181 --partitions 4 --replication-factor 1 && \
                       kafka-topics --create --topic requests --if-not-exists --zookeeper zookeeper:32181 --partitions 4 --replication-factor 1 && \
                       kafka-topics --create --topic requestevents --if-not-exists --zookeeper zookeeper:32181 --partitions 4 --replication-factor 1 && \
                       kafka-topics --create --topic request-events --if-not-exists --zookeeper zookeeper:32181 --partitions 4 --replication-factor 1 && \
                       sleep infinity'"
    environment:
      # The following settings are listed here only to satisfy the image's requirements.
      # We override the image's `command` anyways, hence this container will not start a broker.
      KAFKA_BROKER_ID: ignored
      KAFKA_ZOOKEEPER_CONNECT: ignored
    extra_hosts:
      - "moby:127.0.0.1"
      - "localhost: 127.0.0.1"

  # simple stream processing app that takes events looks at the type of event and if it's a 
  # purchase request it separates it out into the 'requests' kafka topic
  filter-requests:
    hostname: filter-requests
    build: ./kafka_stream_apps/filter_requests/
    #image: ml_pipeline_prototype_filter-requests:latest
    depends_on:
      - kafka
      - zookeeper
      - kafka-create-topics
    ports:
      - "29093:29093"
    extra_hosts:
      - "moby:127.0.0.1"
      - "localhost: 127.0.0.1"

  # simple stream processing app that joins requests and events to make a sliding window containing the user's events 60 mins before the request
  request-lookback:
    hostname: filter-requests
    build: ./kafka_stream_apps/request_lookback/
    depends_on:
      - kafka
      - zookeeper
      - kafka-create-topics
      - filter-requests
    ports:
      - "29094:29094"
    extra_hosts:
      - "moby:127.0.0.1"
      - "localhost: 127.0.0.1"
  
  # Runs the Kafka KSQL Server
  ksql-server:
    image: "confluentinc/ksql-cli:5.0.0-beta1"
    hostname: ksql-server
    ports:
      - '8088:8088'
    depends_on:
      - kafka
      - schema-registry
      - kafka-create-topics
    # Note: The container's `run` script will perform the same readiness checks
    # for Kafka and Confluent Schema Registry, but that's ok because they complete fast.
    # The reason we check for readiness here is that we can insert a sleep time
    # for topic creation before we start the application.
    command: "bash -c 'echo Waiting for Kafka to be ready... && \
                       cub kafka-ready -b kafka:29092 1 120 && \
                       echo Waiting for Confluent Schema Registry to be ready... && \
                       cub sr-ready schema-registry 8081 120 && \
                       echo Waiting a few seconds for topic creation to finish... && \
                       sleep 2 && \
                       /usr/bin/ksql-server-start /etc/ksql/ksql-server.properties'"
    environment:
      KSQL_CONFIG_DIR: "/etc/ksql"
      KSQL_OPTS: "-Dbootstrap.servers=kafka:29092 -Dksql.schema.registry.url=http://schema-registry:8081 -Dlisteners=http://0.0.0.0:8088"
      KSQL_LOG4J_OPTS: "-Dlog4j.configuration=file:/etc/ksql/log4j-rolling.properties"

    extra_hosts:
      - "moby:127.0.0.1"
      - "localhost: 127.0.0.1"


  # Runs the KSQL CLI
  ksql-cli:
    image: "confluentinc/ksql-cli:5.0.0-beta1"
    hostname: ksql-cli
    depends_on:
      - kafka
      - schema-registry
      - kafka-create-topics
      - ksql-server
    command: "perl -e 'while(1){ sleep 99999 }'"
    environment:
      KSQL_CONFIG_DIR: "/etc/ksql"
      KSQL_LOG4J_OPTS: "-Dlog4j.configuration=file:/etc/ksql/log4j-rolling.properties"
      STREAMS_BOOTSTRAP_SERVERS: kafka:29092
      STREAMS_SCHEMA_REGISTRY_HOST: schema-registry
      STREAMS_SCHEMA_REGISTRY_PORT: 8081
    extra_hosts:
      - "moby:127.0.0.1"
      - "localhost: 127.0.0.1"
  
  # Runs the interface for interactive KSQL streaming queries
  ksql-ui:
    image: "confluentinc/ksql-cli:0.5"
    hostname: ksql-ui
    ports:
      - '8082:8082'
    depends_on:
      - kafka
      - schema-registry
      - kafka-create-topics
      - ksql-server
    command: "bash -c 'cd /usr/bin/ && mkdir ui && cd ui &&  wget https://s3.amazonaws.com/ksql-experimental-ui/ksql-experimental-ui-0.1.war && \
   										 echo bootstrap.servers=kafka:29092 > /etc/ksql/ksqlserver.properties ; \
                       echo application.id=ksql_server_quickstart >> /etc/ksql/ksqlserver.properties ; \
                       echo ksql.command.topic.suffix=commands >> /etc/ksql/ksqlserver.properties ; \
                       echo listeners=http://0.0.0.0:8082 >> /etc/ksql/ksqlserver.properties ; \
                       echo ui.enabled=true >> /etc/ksql/ksqlserver.properties ; \
                       pushd /tmp && wget http://get.arcadiadata.com/ksql/clickstream-schema.sql && popd && \
                       cd .. && /usr/bin/ksql-server-start /etc/ksql/ksqlserver.properties'"
    environment:
      KSQL_CONFIG_DIR: "/etc/ksql"
      KSQL_LOG4J_OPTS: "-Dlog4j.configuration=file:/etc/ksql/log4j-rolling.properties"
      STREAMS_BOOTSTRAP_SERVERS: kafka:29092
      STREAMS_SCHEMA_REGISTRY_HOST: schema-registry
      STREAMS_SCHEMA_REGISTRY_PORT: 8081
    extra_hosts:
      - "moby:127.0.0.1"
      - "localhost: 127.0.0.1"

  # launches and starts sending events to kafka from 10 concurrent sessions
  generate-events:
    build: ./generate_events/
    depends_on:
      - kafka
      - zookeeper
      - kafka-create-topics
    hostname: generate-events
    ports:
      - "29990:9990"
    stdin_open: true
    tty: true
    extra_hosts:
      - "moby:127.0.0.1"
      - "localhost: 127.0.0.1"

  # redis database to capture kafka events for displaying charts
  redis:
    image: redis
    depends_on:
      - kafka
      - zookeeper
      - kafka-create-topics
      - generate-events
    hostname: redis
    ports:
      - "6379:6379"
    stdin_open: true
    tty: true
    extra_hosts:
      - "moby:127.0.0.1"
      - "localhost: 127.0.0.1"

  # execute streaming queries on the KSQL server
  run-ksql-queries:
    build: ./run_ksql_queries/
    depends_on:
      - kafka
      - zookeeper
      - kafka-create-topics
      - generate-events
      - ksql-server
    hostname: run-ksql-queries
    stdin_open: true
    tty: true
    extra_hosts:
      - "moby:127.0.0.1"
      - "localhost: 127.0.0.1"

  # aggregate all events in redis
  aggregate-events:
    build: ./aggregate_all_events/
    depends_on:
      - kafka
      - zookeeper
      - kafka-create-topics
      - generate-events
      - redis
    hostname: aggregate-events
    stdin_open: true
    tty: true
    extra_hosts:
      - "moby:127.0.0.1"
      - "localhost: 127.0.0.1"

  # aggregate user events in redis
  aggregate-user-events:
    build: ./aggregate_user_events/
    depends_on:
      - kafka
      - zookeeper
      - kafka-create-topics
      - generate-events
      - redis
    hostname: aggregate-user-events
    stdin_open: true
    tty: true
    extra_hosts:
      - "moby:127.0.0.1"
      - "localhost: 127.0.0.1"

  # streaming dashboard
  event-dashboard:
    build: ./dashboard/
    depends_on:
      - kafka
      - zookeeper
      - kafka-create-topics
      - generate-events
      - redis
      - aggregate-events
      - aggregate-user-events
    hostname: dashboard
    ports:
      - "8050:8050"
    stdin_open: true
    tty: true
    extra_hosts:
      - "moby:127.0.0.1"
      - "localhost: 127.0.0.1"

  
